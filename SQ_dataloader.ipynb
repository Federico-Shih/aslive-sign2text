{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DLcJPD18A7i8"
      },
      "outputs": [],
      "source": [
        "# !pip install torchcodec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhU8FbgyHW4L",
        "outputId": "7e2a83d5-4faa-49f0-f9bd-b0d33d338133"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from torchcodec.decoders import VideoDecoder\n",
        "\n",
        "class WLASLTorchCodec(Dataset):\n",
        "  def __init__(self, json_path, video_dir, split=\"train\", num_frames=32, transform=None):\n",
        "    self.video_dir = video_dir\n",
        "    self.num_frames = num_frames\n",
        "    self.transform = transform\n",
        "\n",
        "    # Read json\n",
        "    with open(json_path, \"r\") as f:\n",
        "      data = json.load(f)\n",
        "\n",
        "    self.samples = []\n",
        "    self.label_map = {}\n",
        "    label_id = 0\n",
        "\n",
        "    for entry in data:\n",
        "      gloss = entry[\"gloss\"]\n",
        "\n",
        "      if gloss not in self.label_map:\n",
        "        self.label_map[gloss] = label_id\n",
        "        label_id += 1\n",
        "\n",
        "      label = self.label_map[gloss]\n",
        "\n",
        "      for inst in entry[\"instances\"]:\n",
        "        if inst[\"split\"] != split:\n",
        "          continue\n",
        "\n",
        "        video_id = inst[\"video_id\"]\n",
        "        file_path = os.path.join(video_dir, f\"{video_id}.mp4\")\n",
        "\n",
        "        if os.path.isfile(file_path):\n",
        "          self.samples.append((file_path, label))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.samples)\n",
        "\n",
        "  def _sample_frames(self, frames):\n",
        "    \"\"\"frames is a list of PIL images or Tensors.\"\"\"\n",
        "    T = len(frames)\n",
        "    idx = torch.linspace(0, T - 1, self.num_frames).long()\n",
        "    return [frames[i] for i in idx]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    video_path, label = self.samples[idx]\n",
        "\n",
        "    decoder = VideoDecoder(video_path)\n",
        "\n",
        "    frames = []\n",
        "    for chunk in decoder:\n",
        "      # chunk is a Tensor of frames: (T, H, W) OR (T, H, W, C)\n",
        "      for frame_tensor in chunk:\n",
        "        # Handle grayscale frames (H, W)\n",
        "        if frame_tensor.dim() == 2:\n",
        "          frame_tensor = frame_tensor.unsqueeze(2)  # â†’ (H, W, 1)\n",
        "\n",
        "        # Handle RGB frames (H, W, C)\n",
        "        if frame_tensor.dim() == 3:\n",
        "          pass\n",
        "        else:\n",
        "          raise ValueError(f\"Unexpected frame shape: {frame_tensor.shape}\")\n",
        "\n",
        "        # Convert to C x H x W\n",
        "        frame_chw = frame_tensor.permute(2, 0, 1)\n",
        "\n",
        "        frame_pil = transforms.ToPILImage()(frame_chw)\n",
        "        frames.append(frame_pil)\n",
        "\n",
        "    # Guard for short videos\n",
        "    if len(frames) < self.num_frames:\n",
        "        while len(frames) < self.num_frames:\n",
        "            frames.extend(frames)\n",
        "        frames = frames[: self.num_frames]\n",
        "\n",
        "    # Uniform sampling\n",
        "    frames = self._sample_frames(frames)\n",
        "\n",
        "    if self.transform:\n",
        "      frames = torch.stack([self.transform(f) for f in frames])\n",
        "    else:\n",
        "      frames = torch.stack([transforms.ToTensor()(f) for f in frames])\n",
        "\n",
        "    return frames, label\n"
      ],
      "metadata": {
        "id": "ucRGVaHIDteS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to json file in drive\n",
        "json_path = \"/content/drive/My Drive/Colab Notebooks/WLASL_v0.3.json\"\n",
        "\n",
        "with open(json_path, \"r\") as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "if \"root\" in data:\n",
        "  data = data[\"root\"]\n",
        "\n",
        "# Create dataset\n",
        "dataset = WLASLTorchCodec(\n",
        "  json_path=json_path,\n",
        "  video_dir=\"/content/drive/My Drive/Colab Notebooks/videos\",\n",
        "  split=\"train\",\n",
        "  num_frames=8\n",
        ")\n",
        "\n",
        "# Test a sample\n",
        "frames, label = dataset[0]\n",
        "print(\"Frames shape:\", frames.shape)\n",
        "print(\"Label:\", label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cRqrr_aIu7R",
        "outputId": "ed2c4240-dbad-49a6-f100-ca256b5adaa6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames shape: torch.Size([8, 1, 256, 256])\n",
            "Label: 0\n"
          ]
        }
      ]
    }
  ]
}