{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Luwl8hSq-lmd"
      },
      "source": [
        "# ASLive Sign2Text Model\n",
        "\n",
        "This notebook implements the sign language to text model following the architecture:\n",
        "- **Vision Layer (CNN)**: Extracts spatial features from each frame\n",
        "- **Positional Encoding (PE)**: Adds temporal position information\n",
        "- **Attention Layer (LSTM)**: Processes temporal sequence with attention\n",
        "- **FC Layer**: Final classification layer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub torchcodec torchvision\n",
        "!pip install git+https://github.com/facebookresearch/pytorchvideo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbsKbY7bA16g",
        "outputId": "5a7e46a8-5a98-4ffc-fab8-7837ee66f1ff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Collecting torchcodec\n",
            "  Downloading torchcodec-0.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.9.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.9.0+cu126)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0->torchvision) (3.0.3)\n",
            "Downloading torchcodec-0.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchcodec\n",
            "Successfully installed torchcodec-0.9.0\n",
            "Collecting git+https://github.com/facebookresearch/pytorchvideo\n",
            "  Cloning https://github.com/facebookresearch/pytorchvideo to /tmp/pip-req-build-jdslzkjl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/pytorchvideo /tmp/pip-req-build-jdslzkjl\n",
            "  Resolved https://github.com/facebookresearch/pytorchvideo to commit 0f9a5e102e4d84972b829fd30e3c3f78c7c7fd1a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fvcore (from pytorchvideo==0.1.5)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting av (from pytorchvideo==0.1.5)\n",
            "  Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting parameterized (from pytorchvideo==0.1.5)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting iopath (from pytorchvideo==0.1.5)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pytorchvideo==0.1.5) (3.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fvcore->pytorchvideo==0.1.5) (2.0.2)\n",
            "Collecting yacs>=0.1.6 (from fvcore->pytorchvideo==0.1.5)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from fvcore->pytorchvideo==0.1.5) (6.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from fvcore->pytorchvideo==0.1.5) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from fvcore->pytorchvideo==0.1.5) (3.2.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from fvcore->pytorchvideo==0.1.5) (11.3.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from fvcore->pytorchvideo==0.1.5) (0.9.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from iopath->pytorchvideo==0.1.5) (4.15.0)\n",
            "Collecting portalocker (from iopath->pytorchvideo==0.1.5)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (40.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: pytorchvideo, fvcore, iopath\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=213017 sha256=0cea744f15e64a1a2c2d7a7fce871daba3b506ddb38e75661a9196fc7cc32546\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ducrczab/wheels/98/ed/57/db54871bbb5a7356f816cf5ec47ab2d3ca2a86fea760a0cbd8\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=1a2b87af6ec2fdf4cb73437883af45efe95f86b20f096be824107330fa700a15\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/9f/a5/e4f5b27454ccd4596bd8b62432c7d6b1ca9fa22aef9d70a16a\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=29f5f1c758b43ce80060c3b1c8005fc7f9e0a3ffd9326b620217a0ebc997b9b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/96/04/4f5f31ff812f684f69f40cb1634357812220aac58d4698048c\n",
            "Successfully built pytorchvideo fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, parameterized, av, iopath, fvcore, pytorchvideo\n",
            "Successfully installed av-16.0.1 fvcore-0.1.5.post20221221 iopath-0.1.10 parameterized-0.9.0 portalocker-3.2.0 pytorchvideo-0.1.5 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Before running, add everything from SQ_dataloader.ipynb into the cell below and run"
      ],
      "metadata": {
        "id": "8q1A9uXSU7qG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtCIKfOn-lmh"
      },
      "source": [
        "## 1. Data Loading (from SQ_dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#add SQ_dataloader code here\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from torchcodec.decoders import VideoDecoder\n",
        "import kagglehub\n",
        "import os\n",
        "import json\n",
        "\n",
        "import torch # Assuming torch is imported elsewhere\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from torchcodec.decoders import VideoDecoder\n",
        "import kagglehub\n",
        "import os\n",
        "import json\n",
        "from PIL import Image # Needed for cropping if working with PIL images\n",
        "\n",
        "class WLASLTorchCodec(Dataset):\n",
        "  download_path = None\n",
        "\n",
        "  def __init__(self, json_path=None, video_dir=None, download=True, max_classes=None, split=\"train\", num_frames=32, transform=None):\n",
        "    print(\"Will download:\", download)\n",
        "    if (json_path is None or video_dir is None) and download == False:\n",
        "      raise ValueError(\"json_path and video_dir must be provided with download false\")\n",
        "    if download:\n",
        "      if WLASLTorchCodec.download_path is None:\n",
        "        path = kagglehub.dataset_download(\"sttaseen/wlasl2000-resized\")\n",
        "        WLASLTorchCodec.download_path = path\n",
        "      else:\n",
        "        path = WLASLTorchCodec.download_path\n",
        "      print(\"Downloaded at path: \", path)\n",
        "\n",
        "      self.video_dir = os.path.join(path, \"wlasl-complete\", \"videos\")\n",
        "      json_path = os.path.join(path, \"wlasl-complete\",\"WLASL_v0.3.json\")\n",
        "      downloaded = True\n",
        "    else:\n",
        "      self.video_dir = video_dir\n",
        "    self.num_frames = num_frames\n",
        "    self.transform = transform\n",
        "\n",
        "    # Read json\n",
        "    with open(json_path, \"r\") as f:\n",
        "      data = json.load(f)\n",
        "    if max_classes is not None:\n",
        "        if isinstance(max_classes, int):\n",
        "            # Keep only the first N entries (Usually the most frequent in WLASL)\n",
        "            data = data[:max_classes]\n",
        "            print(f\"Limiting dataset to top {max_classes} classes.\")\n",
        "        elif isinstance(max_classes, list):\n",
        "            # Keep only entries that match specific glosses\n",
        "            data = [entry for entry in data if entry['gloss'] in max_classes]\n",
        "            print(f\"Limiting dataset to {len(data)} specific classes.\")\n",
        "    self.samples = []\n",
        "    self.label_map = {}\n",
        "    label_id = 0\n",
        "\n",
        "    for entry in data:\n",
        "      gloss = entry[\"gloss\"]\n",
        "\n",
        "      if gloss not in self.label_map:\n",
        "        self.label_map[gloss] = label_id\n",
        "        label_id += 1\n",
        "\n",
        "      label = self.label_map[gloss]\n",
        "\n",
        "      for inst in entry[\"instances\"]:\n",
        "        if inst[\"split\"] != split:\n",
        "          continue\n",
        "\n",
        "        video_id = inst[\"video_id\"]\n",
        "        file_path = os.path.join(self.video_dir, f\"{video_id}.mp4\")\n",
        "\n",
        "        # 1. Modification in __init__: Extract and store frame/bbox info\n",
        "        frame_start = inst.get(\"frame_start\", 1) # Default to 1 if missing\n",
        "        frame_end = inst.get(\"frame_end\", -1)   # Default to -1 if missing\n",
        "        bbox = inst.get(\"bbox\", [0, 0, 1.0, 1.0]) # Default to normalized full frame if missing\n",
        "\n",
        "        if os.path.isfile(file_path):\n",
        "          # Store a tuple of (file_path, label, frame_start, frame_end, bbox)\n",
        "          self.samples.append((file_path, label, frame_start, frame_end, bbox))\n",
        "        self.num_classes = label_id\n",
        "  def __len__(self):\n",
        "    return len(self.samples)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # 2. Modification in __getitem__: Unpack all instance info\n",
        "    video_path, label, frame_start, frame_end, bbox = self.samples[idx]\n",
        "\n",
        "    # Convert WLASL 1-based indices (inclusive start, exclusive end) to\n",
        "    # torchcodec's 0-based indices (inclusive start, inclusive end).\n",
        "\n",
        "    decoder = VideoDecoder(video_path)\n",
        "    video_length = decoder.metadata.num_frames\n",
        "    end_frame = frame_end - 1 if frame_end > 0 else video_length\n",
        "    start_frame = 0\n",
        "    if end_frame > video_length:\n",
        "      end_frame = video_length\n",
        "    else:\n",
        "      end_frame = frame_end - 2 if frame_end > 0 else None\n",
        "    if frame_start > video_length:\n",
        "      start_frame = 0\n",
        "    else:\n",
        "      start_frame = frame_start - 1\n",
        "    frames = decoder[start_frame:end_frame]\n",
        "    if self.transform:\n",
        "      # Transform should handle T x C x H x W input\n",
        "      frames = self.transform(frames)\n",
        "    return frames, torch.tensor(label) # Ensure label is a tensor"
      ],
      "metadata": {
        "id": "vqaVkQmlVJE0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorchvideo.transforms as ptv_transforms\n",
        "from torchvision.transforms import Compose, Lambda\n",
        "\n",
        "\n",
        "mean = [0.45, 0.45, 0.45]\n",
        "std = [0.225, 0.225, 0.225]\n",
        "\n",
        "# Test out dataset\n",
        "train_transform = Compose(\n",
        "    [\n",
        "        # 1. Spatial Resize: Scale the shortest edge to SIDE_SIZE\n",
        "        ptv_transforms.UniformTemporalSubsample(num_samples=24, temporal_dim=0),\n",
        "        ptv_transforms.ConvertUint8ToFloat(),\n",
        "        Lambda(lambda x: x.permute(1, 0, 2, 3)),\n",
        "        ptv_transforms.Normalize(mean, std),\n",
        "        Lambda(lambda x: x.permute(1, 0, 2, 3)),\n",
        "        ptv_transforms.ShortSideScale(size=224),\n",
        "        # ptv_transforms.RandAugment(magnitude=6, num_layers=2),\n",
        "        # ptv_transforms.AugMix(magnitude=3),\n",
        "    ]\n",
        ")\n",
        "\n",
        "def show_frame(video, frame_idx):\n",
        "  import matplotlib.pyplot as plt\n",
        "  import numpy as np\n",
        "  single_frame = video[frame_idx]\n",
        "  frame_np = single_frame.detach().cpu().numpy()\n",
        "\n",
        "  frame_np = np.transpose(frame_np, (1, 2, 0))\n",
        "  plt.figure(figsize=(5, 5))\n",
        "  plt.imshow(frame_np)\n",
        "  plt.title(f'Frame {frame_idx} from Video Batch')\n",
        "  plt.axis('off') # Hide axis ticks and labels\n",
        "  plt.show()\n",
        "\n",
        "# clip = WLASLTorchCodec(max_classes=1, transform=train_transform)\n",
        "\n",
        "# for video, label in clip:\n",
        "#   show_frame(video, 0)"
      ],
      "metadata": {
        "id": "wK-FFUttRVGu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsdOaDCZ-lmh",
        "outputId": "d0a8f0c7-2f79-46ec-a27e-0751950828e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from torchcodec.decoders import VideoDecoder\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tfGCzOb-lmi"
      },
      "source": [
        "## 2. Vision Layer (CNN Backbone)\n",
        "\n",
        "The Vision Layer extracts spatial features from each video frame using a CNN. We use a pretrained ResNet-18 as the backbone and remove the final classification layer to get feature embeddings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jkESoYf_-lmi"
      },
      "outputs": [],
      "source": [
        "class VisionLayer(nn.Module):\n",
        "    \"\"\"CNN backbone for extracting spatial features from video frames.\n",
        "\n",
        "    Uses pretrained ResNet-18 as feature extractor.\n",
        "    Input: (batch, T, C, H, W) - batch of T frames\n",
        "    Output: (batch, T, feature_dim) - feature vectors for each frame\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_dim=512, pretrained=True, freeze_backbone=False):\n",
        "        super(VisionLayer, self).__init__()\n",
        "\n",
        "        # Load pretrained ResNet-18\n",
        "        resnet = models.resnet18(weights='IMAGENET1K_V1' if pretrained else None)\n",
        "\n",
        "        # Remove the final FC layer\n",
        "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "\n",
        "        # ResNet-18 outputs 512-dim features\n",
        "        self.resnet_feature_dim = 512\n",
        "\n",
        "        # Optional projection layer to adjust feature dimension\n",
        "        if feature_dim != self.resnet_feature_dim:\n",
        "            self.projection = nn.Linear(self.resnet_feature_dim, feature_dim)\n",
        "        else:\n",
        "            self.projection = None\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "\n",
        "        # Freeze backbone if specified\n",
        "        self.set_freeze_backbone(freeze_backbone)\n",
        "\n",
        "    def set_freeze_backbone(self, is_frozen):\n",
        "      for param in self.backbone.parameters():\n",
        "          param.requires_grad = not is_frozen\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor of shape (batch, T, C, H, W)\n",
        "        Returns:\n",
        "            Feature tensor of shape (batch, T, feature_dim)\n",
        "        \"\"\"\n",
        "        batch_size, T, C, H, W = x.shape\n",
        "\n",
        "        # Reshape to process all frames together: (batch * T, C, H, W)\n",
        "        x = x.view(batch_size * T, C, H, W)\n",
        "\n",
        "        # Extract features: (batch * T, 512, 1, 1)\n",
        "        features = self.backbone(x)\n",
        "\n",
        "        # Flatten: (batch * T, 512)\n",
        "        features = features.view(batch_size * T, -1)\n",
        "\n",
        "        # Project features if needed\n",
        "        if self.projection is not None:\n",
        "            features = self.projection(features)\n",
        "\n",
        "        # Reshape back: (batch, T, feature_dim)\n",
        "        features = features.view(batch_size, T, self.feature_dim)\n",
        "\n",
        "        return features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIkvk_iX-lmj"
      },
      "source": [
        "## 3. Positional Encoding (PE)\n",
        "\n",
        "Sinusoidal positional encoding adds temporal position information to the frame features before feeding them to the LSTM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cfVsdetA-lmj"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"Sinusoidal positional encoding for temporal sequences.\n",
        "\n",
        "    Adds position information to help the model understand the order of frames.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, max_len=500, dropout=0.1):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        # self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Create positional encoding matrix\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # Add batch dimension: (1, max_len, d_model)\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        # Register as buffer (not a parameter, but should be saved/loaded)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor of shape (batch, T, d_model)\n",
        "        Returns:\n",
        "            Tensor with positional encoding added: (batch, T, d_model)\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVq1WNB1-lmj"
      },
      "source": [
        "## 4. Attention Layer (LSTM with Attention)\n",
        "\n",
        "Bidirectional LSTM processes the sequence of frame features, followed by an attention mechanism to weight the importance of different time steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HCrnK27J-lmj"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Attention(nn.Module):\n",
        "    \"\"\"Attention mechanism for weighting LSTM outputs.\n",
        "\n",
        "    Computes attention weights over the sequence and returns a weighted sum.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_dim // 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, lstm_output):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            lstm_output: LSTM outputs of shape (batch, T, hidden_dim)\n",
        "        Returns:\n",
        "            context: Weighted sum of shape (batch, hidden_dim)\n",
        "            attention_weights: Attention weights of shape (batch, T)\n",
        "        \"\"\"\n",
        "        # Compute attention scores: (batch, T, 1)\n",
        "        scores = self.attention(lstm_output)\n",
        "\n",
        "        # Apply softmax over time dimension: (batch, T, 1)\n",
        "        attention_weights = F.softmax(scores, dim=1)\n",
        "\n",
        "        # Compute weighted sum: (batch, hidden_dim)\n",
        "        context = torch.sum(attention_weights * lstm_output, dim=1)\n",
        "\n",
        "        return context, attention_weights.squeeze(-1)\n",
        "\n",
        "\n",
        "class AttentionLSTM(nn.Module):\n",
        "    \"\"\"Bidirectional LSTM with attention mechanism.\n",
        "\n",
        "    Processes temporal sequence of frame features and outputs a fixed-size representation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim=256, num_layers=2, dropout=0.3, bidirectional=True):\n",
        "        super(AttentionLSTM, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.attention = Attention(hidden_dim * self.num_directions)\n",
        "\n",
        "        # Output dimension\n",
        "        self.output_dim = hidden_dim * self.num_directions\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor of shape (batch, T, input_dim)\n",
        "        Returns:\n",
        "            output: Context vector of shape (batch, hidden_dim * num_directions)\n",
        "            attention_weights: Attention weights of shape (batch, T)\n",
        "        \"\"\"\n",
        "        # LSTM forward pass: (batch, T, hidden_dim * num_directions)\n",
        "        lstm_output, (hidden, cell) = self.lstm(x)\n",
        "\n",
        "        # Apply attention\n",
        "        context, attention_weights = self.attention(lstm_output)\n",
        "\n",
        "        return context, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXNLX5GV-lmj"
      },
      "source": [
        "## 5. Complete Sign2Text Model\n",
        "\n",
        "Combines all components: Vision Layer → Positional Encoding → Attention LSTM → FC Layer → Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Sign2TextModel(nn.Module):\n",
        "    \"\"\"Complete Sign Language to Text model.\n",
        "\n",
        "    Architecture:\n",
        "    1. Vision Layer (CNN): Extract spatial features from each frame\n",
        "    2. Positional Encoding: Add temporal position information\n",
        "    3. Attention LSTM: Process temporal sequence with attention\n",
        "    4. FC Layer: Final classification\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, feature_dim=512, hidden_dim=256,\n",
        "                 num_lstm_layers=2, dropout=0.3, pretrained_cnn=True,\n",
        "                 classification_layers=(256,),\n",
        "                 freeze_cnn=False, max_frames=100):\n",
        "        super(Sign2TextModel, self).__init__()\n",
        "\n",
        "        # Vision Layer (CNN)\n",
        "        self.vision_layer = VisionLayer(\n",
        "            feature_dim=feature_dim,\n",
        "            pretrained=pretrained_cnn,\n",
        "            freeze_backbone=freeze_cnn\n",
        "        )\n",
        "\n",
        "        # Positional Encoding\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            d_model=feature_dim,\n",
        "            max_len=100,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        # Attention Layer (LSTM)\n",
        "        self.attention_lstm = AttentionLSTM(\n",
        "            input_dim=feature_dim,\n",
        "            hidden_dim=hidden_dim,\n",
        "            num_layers=num_lstm_layers,\n",
        "            dropout=dropout,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        layers = []\n",
        "        self.lstm_ln = nn.LayerNorm(hidden_dim * 2)\n",
        "        input_dim = self.attention_lstm.output_dim\n",
        "        for i, dim in enumerate(classification_layers):\n",
        "            layers.append(nn.Linear(input_dim, dim))\n",
        "            layers.append(nn.BatchNorm1d(dim))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            input_dim = dim\n",
        "\n",
        "        layers.append(nn.Linear(input_dim, num_classes))\n",
        "        # FC Layer (Classification)\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            *layers\n",
        "        )\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def set_freeze(self, is_frozen):\n",
        "        self.vision_layer.set_freeze_backbone(is_frozen)\n",
        "\n",
        "    def forward(self, x, return_attention=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input video frames of shape (batch, T, C, H, W)\n",
        "            return_attention: If True, also return attention weights\n",
        "        Returns:\n",
        "            logits: Classification logits of shape (batch, num_classes)\n",
        "            attention_weights (optional): Attention weights of shape (batch, T)\n",
        "        \"\"\"\n",
        "        # Vision Layer: (batch, T, C, H, W) → (batch, T, feature_dim)\n",
        "        features = self.vision_layer(x)\n",
        "\n",
        "        # Positional Encoding: (batch, T, feature_dim) → (batch, T, feature_dim)\n",
        "        features = self.positional_encoding(features)\n",
        "\n",
        "        # Attention LSTM: (batch, T, feature_dim) → (batch, hidden_dim * 2)\n",
        "        context, attention_weights = self.attention_lstm(features)\n",
        "\n",
        "        # FC Layer: (batch, hidden_dim * 2) → (batch, num_classes)\n",
        "        logits = self.fc_layer(context)\n",
        "\n",
        "        if return_attention:\n",
        "            return logits, attention_weights\n",
        "        return logits\n",
        "\n",
        "    def _init_weights(self):\n",
        "        \"\"\"Applies Xavier initialization to Linear layers and LSTM weights.\"\"\"\n",
        "\n",
        "        # Initialize LSTM weights\n",
        "        # For LSTMs, orthogonal initialization for recurrent weights and Xavier for input weights is common.\n",
        "        # However, nn.init.xavier_uniform_ is a good general starting point.\n",
        "        for name, param in self.attention_lstm.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                # Apply Xavier/Glorot for weights\n",
        "                nn.init.xavier_uniform_(param)\n",
        "            elif 'bias' in name:\n",
        "                # Initialize biases to zero (or use a specific trick like setting forget gate bias to 1)\n",
        "                nn.init.constant_(param, 0.0)\n",
        "\n",
        "        # Initialize Classification FC Layers\n",
        "        for m in self.fc_layer.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                # Use Xavier/Glorot for weights\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0.0)"
      ],
      "metadata": {
        "id": "VdpKSoUFhmo9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srRI42gq-lmk"
      },
      "source": [
        "## 6. Training Utilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6UWY8AUW-lmk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d43ab09-a522-4156-defb-d8147d9510ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3634111461.py:2: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        }
      ],
      "source": [
        "from torch.cuda.amp import autocast, GradScaler\n",
        "scaler = GradScaler()\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    \"\"\"Train the model for one epoch.\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
        "    for frames, labels in progress_bar:\n",
        "        frames = frames.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # print(frames.shape)\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        with autocast():\n",
        "          outputs = model(frames)\n",
        "          loss = criterion(outputs, labels)\n",
        "        # Backward pass\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        running_loss += loss.item() * frames.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        progress_bar.set_postfix({\n",
        "            'loss': loss.item(),\n",
        "            'acc': 100 * correct / total\n",
        "        })\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = 100 * correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    \"\"\"Evaluate the model on a dataset.\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for frames, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            frames = frames.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            with autocast():\n",
        "                outputs = model(frames)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * frames.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = 100 * correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFBEBTg4-lml"
      },
      "source": [
        "## 7. Configuration and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kPsZzTQd-lml"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# CONFIGURATION - Modify these paths and hyperparameters\n",
        "# ============================================\n",
        "\n",
        "# Data paths\n",
        "JSON_PATH = \"/content/drive/MyDrive/wlasl_resized/wlasl-complete/WLASL_v0.3.json\"  # Path to WLASL JSON\n",
        "VIDEO_DIR = \"/content/drive/MyDrive/wlasl_resized/wlasl-complete/videos\"  # Path to video directory\n",
        "\n",
        "# Model hyperparameters\n",
        "NUM_FRAMES = 24           # Number of frames to sample from each video\n",
        "FEATURE_DIM = 512        # CNN feature dimension\n",
        "HIDDEN_DIM = 256         # LSTM hidden dimension\n",
        "NUM_LSTM_LAYERS = 2      # Number of LSTM layers\n",
        "DROPOUT = 0.3            # Dropout rate\n",
        "\n",
        "# Training hyperparameters\n",
        "BATCH_SIZE = 18           # Batch size (adjust based on GPU memory)\n",
        "LEARNING_RATE = 5e-4     # Learning rate\n",
        "NUM_EPOCHS = 200          # Number of training epochs\n",
        "WEIGHT_DECAY = 1e-3     # L2 regularization\n",
        "IMG_SIZE=224\n",
        "# Options\n",
        "FREEZE_CNN = True       # Whether to freeze CNN backbone\n",
        "PRETRAINED_CNN = True    # Use pretrained CNN weights\n",
        "WORKERS = 10\n",
        "EPOCHS_UNTIL_UNFREEZE = 50\n",
        "CLASSES_COUNT = 50\n",
        "PREFETCH = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "l39WEIDb-lml"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import v2\n",
        "# Data transforms for training and validation\n",
        "# train_transform = transforms.Compose([\n",
        "#     v2.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "#     # v2.RandomHorizontalFlip(),\n",
        "#     # v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "#     v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
        "# ])\n",
        "\n",
        "# val_transform = transforms.Compose([\n",
        "#     v2.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "#     v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
        "# ])\n",
        "\n",
        "from torchvision.transforms import Compose\n",
        "import pytorchvideo.transforms as ptv_transforms\n",
        "from pytorchvideo.transforms import functional as ptv_functional\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Note: The transforms below expect the video tensor to be in the range [0.0, 1.0]\n",
        "# and of shape (T, C, H, W). The `WLASLTorchCodec` implementation already ensures\n",
        "# the shape is (T, C, H, W), but you must ensure the pixel values are converted\n",
        "# to float and normalized to [0, 1] before applying the standard normalization.\n",
        "\n",
        "\n",
        "\n",
        "mean = [0.45, 0.45, 0.45]\n",
        "std = [0.225, 0.225, 0.225]\n",
        "\n",
        "# Test out dataset\n",
        "train_transform = Compose(\n",
        "    [\n",
        "        # 1. Spatial Resize: Scale the shortest edge to SIDE_SIZE\n",
        "        ptv_transforms.UniformTemporalSubsample(num_samples=NUM_FRAMES, temporal_dim=0),\n",
        "        ptv_transforms.ConvertUint8ToFloat(),\n",
        "        Lambda(lambda x: x.permute(1, 0, 2, 3)),\n",
        "        ptv_transforms.Normalize(mean, std),\n",
        "        Lambda(lambda x: x.permute(1, 0, 2, 3)),\n",
        "        ptv_transforms.ShortSideScale(size=IMG_SIZE),\n",
        "        ptv_transforms.RandAugment(magnitude=9, num_layers=2, prob=0.6),\n",
        "        # ptv_transforms.AugMix(magnitude=3),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# train_transform = Compose(\n",
        "#     [\n",
        "#         # 1. Spatial Resize: Scale the shortest edge to SIDE_SIZE\n",
        "#         ptv_transforms.UniformTemporalSubsample(num_samples=NUM_FRAMES, temporal_dim=0),\n",
        "#         ptv_transforms.ConvertUint8ToFloat(),\n",
        "#         ptv_transforms.ShortSideScale(size=IMG_SIZE),\n",
        "#         ptv_transforms.RandAugment(magnitude=15, num_layers=2),\n",
        "#         ptv_transforms.AugMix(magnitude=3),\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "test_transform = Compose(\n",
        "    [\n",
        "        ptv_transforms.UniformTemporalSubsample(num_samples=NUM_FRAMES, temporal_dim=0),\n",
        "        ptv_transforms.ConvertUint8ToFloat(),\n",
        "        Lambda(lambda x: x.permute(1, 0, 2, 3)),\n",
        "        ptv_transforms.Normalize(mean, std),\n",
        "        Lambda(lambda x: x.permute(1, 0, 2, 3)),\n",
        "        ptv_transforms.ShortSideScale(size=IMG_SIZE),\n",
        "    ]\n",
        ")\n",
        "val_transform =test_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnohaoY9-lml",
        "outputId": "6a1e09dd-990c-4fa4-af2f-b027121c6deb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Will download: True\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/sttaseen/wlasl2000-resized?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.87G/1.87G [00:48<00:00, 41.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded at path:  /root/.cache/kagglehub/datasets/sttaseen/wlasl2000-resized/versions/1\n",
            "Limiting dataset to top 50 classes.\n",
            "Will download: True\n",
            "Downloaded at path:  /root/.cache/kagglehub/datasets/sttaseen/wlasl2000-resized/versions/1\n",
            "Limiting dataset to top 50 classes.\n",
            "Will download: True\n",
            "Downloaded at path:  /root/.cache/kagglehub/datasets/sttaseen/wlasl2000-resized/versions/1\n",
            "Limiting dataset to top 50 classes.\n",
            "Number of training samples: 785\n",
            "Number of validation samples: 183\n",
            "Number of test samples: 143\n",
            "Number of classes: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Create datasets\n",
        "train_dataset = WLASLTorchCodec(\n",
        "    download=True,\n",
        "    split=\"train\",\n",
        "    max_classes=CLASSES_COUNT,\n",
        "    num_frames=NUM_FRAMES,\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "val_dataset = WLASLTorchCodec(\n",
        "    download=True,\n",
        "    split=\"val\",\n",
        "    max_classes=CLASSES_COUNT,\n",
        "    num_frames=NUM_FRAMES,\n",
        "    transform=val_transform\n",
        ")\n",
        "\n",
        "test_dataset = WLASLTorchCodec(\n",
        "    download=True,\n",
        "    split=\"test\",\n",
        "    max_classes=CLASSES_COUNT,\n",
        "    num_frames=NUM_FRAMES,\n",
        "    transform=val_transform\n",
        ")\n",
        "\n",
        "# Get number of classes from dataset\n",
        "NUM_CLASSES = train_dataset.num_classes\n",
        "\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of validation samples: {len(val_dataset)}\")\n",
        "print(f\"Number of test samples: {len(test_dataset)}\")\n",
        "print(f\"Number of classes: {NUM_CLASSES}\")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=WORKERS,           # Start high. The optimal value is often 4 to 12.\n",
        "    pin_memory=True,         # Accelerates the transfer of data from CPU to GPU VRAM.\n",
        "    persistent_workers=True, # Recommended for PyTorch multi-process workers to save epoch setup time.\n",
        "    prefetch_factor=PREFETCH\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=WORKERS,           # Start high. The optimal value is often 4 to 12.\n",
        "                             # Since video decoding is CPU-heavy, 8 is a good starting point.\n",
        "    pin_memory=True,         # Accelerates the transfer of data from CPU to GPU VRAM.\n",
        "    persistent_workers=True, # Recommended for PyTorch multi-process workers to save epoch setup time.\n",
        "    prefetch_factor=PREFETCH\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=WORKERS,           # Start high. The optimal value is often 4 to 12.\n",
        "                             # Since video decoding is CPU-heavy, 8 is a good starting point.\n",
        "    pin_memory=True,         # Accelerates the transfer of data from CPU to GPU VRAM.\n",
        "    persistent_workers=True, # Recommended for PyTorch multi-process workers to save epoch setup time.\n",
        "    prefetch_factor=PREFETCH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abGiXTmk-lml",
        "outputId": "27227a65-6546-4e70-e28c-1378fc328f35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 235MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total parameters: 14,607,731\n",
            "Trainable parameters: 3,431,219\n"
          ]
        }
      ],
      "source": [
        "# Initialize model\n",
        "model = Sign2TextModel(\n",
        "    num_classes=NUM_CLASSES,\n",
        "    feature_dim=FEATURE_DIM,\n",
        "    hidden_dim=HIDDEN_DIM,\n",
        "    num_lstm_layers=NUM_LSTM_LAYERS,\n",
        "    dropout=DROPOUT,\n",
        "    pretrained_cnn=PRETRAINED_CNN,\n",
        "    freeze_cnn=FREEZE_CNN,\n",
        "    max_frames=NUM_FRAMES\n",
        ").to(device)\n",
        "\n",
        "# model = SlowFast(num_classes=NUM_CLASSES, dropout=DROPOUT).to(device)\n",
        "\n",
        "# model = SignTimeSformer(\n",
        "#     num_classes=NUM_CLASSES,\n",
        "#     img_size=IMG_SIZE,\n",
        "#     num_frames=NUM_FRAMES,\n",
        "#     heads=12,\n",
        "#     L=5,\n",
        "#     dropout=DROPOUT\n",
        "# ).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW( model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY )\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( optimizer, mode='min', factor=0.3, patience=5 )\n",
        "\n",
        "# Print model summary\n",
        "# print(model)\n",
        "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbpkZSb_-lmm"
      },
      "source": [
        "## 8. Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jbK9sCf-lmm",
        "outputId": "b9dcc56d-e6e8-4e0d-cd18-2d566923f831"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 38/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/44 [00:00<?, ?it/s]/tmp/ipython-input-3634111461.py:20: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training: 100%|██████████| 44/44 [00:20<00:00,  2.19it/s, loss=3.21, acc=20.8]\n",
            "Evaluating:   0%|          | 0/11 [00:00<?, ?it/s]/tmp/ipython-input-3634111461.py:63: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.1076, Train Acc: 20.76%\n",
            "Val Loss: 3.5291, Val Acc: 17.49%\n",
            "✓ Saved new best model with Val Acc: 17.49%\n",
            "\n",
            "Epoch 39/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:20<00:00,  2.16it/s, loss=2.76, acc=21]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.30it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.0185, Train Acc: 21.02%\n",
            "Val Loss: 3.5188, Val Acc: 18.58%\n",
            "✓ Saved new best model with Val Acc: 18.58%\n",
            "\n",
            "Epoch 40/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:20<00:00,  2.18it/s, loss=3.1, acc=21.7]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.07it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.0474, Train Acc: 21.66%\n",
            "Val Loss: 3.5220, Val Acc: 18.03%\n",
            "\n",
            "Epoch 41/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:21<00:00,  2.06it/s, loss=2.9, acc=21.9]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.0127, Train Acc: 21.91%\n",
            "Val Loss: 3.5168, Val Acc: 15.85%\n",
            "\n",
            "Epoch 42/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:20<00:00,  2.12it/s, loss=3.13, acc=21.7]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.24it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.0927, Train Acc: 21.66%\n",
            "Val Loss: 3.5528, Val Acc: 15.85%\n",
            "\n",
            "Epoch 43/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:20<00:00,  2.10it/s, loss=3.03, acc=21.4]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.0497, Train Acc: 21.40%\n",
            "Val Loss: 3.5059, Val Acc: 18.58%\n",
            "\n",
            "Epoch 44/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:20<00:00,  2.12it/s, loss=2.9, acc=19.5]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.29it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.0173, Train Acc: 19.49%\n",
            "Val Loss: 3.5195, Val Acc: 18.58%\n",
            "\n",
            "Epoch 45/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:21<00:00,  2.08it/s, loss=2.76, acc=19.5]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.1113, Train Acc: 19.49%\n",
            "Val Loss: 3.5413, Val Acc: 17.49%\n",
            "\n",
            "Epoch 46/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:20<00:00,  2.13it/s, loss=3.64, acc=22]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.0314, Train Acc: 22.04%\n",
            "Val Loss: 3.5126, Val Acc: 20.22%\n",
            "✓ Saved new best model with Val Acc: 20.22%\n",
            "\n",
            "Epoch 47/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:20<00:00,  2.10it/s, loss=2.49, acc=22.4]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.39it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.9654, Train Acc: 22.42%\n",
            "Val Loss: 3.4984, Val Acc: 16.94%\n",
            "\n",
            "Epoch 48/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:20<00:00,  2.15it/s, loss=3.38, acc=22.7]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.26it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.9767, Train Acc: 22.68%\n",
            "Val Loss: 3.4954, Val Acc: 17.49%\n",
            "\n",
            "Epoch 49/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:20<00:00,  2.11it/s, loss=2.24, acc=25.4]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.9118, Train Acc: 25.35%\n",
            "Val Loss: 3.4478, Val Acc: 17.49%\n",
            "\n",
            "Epoch 50/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:19<00:00,  2.23it/s, loss=2.76, acc=25.4]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.14it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.8917, Train Acc: 25.35%\n",
            "Val Loss: 3.4577, Val Acc: 16.94%\n",
            "\n",
            "Epoch 51/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:20<00:00,  2.19it/s, loss=2.97, acc=23.1]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.20it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.9840, Train Acc: 23.06%\n",
            "Val Loss: 3.4688, Val Acc: 15.85%\n",
            "\n",
            "Epoch 52/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.45it/s, loss=2.49, acc=22.7]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.20it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.9488, Train Acc: 22.68%\n",
            "Val Loss: 3.1983, Val Acc: 21.86%\n",
            "✓ Saved new best model with Val Acc: 21.86%\n",
            "\n",
            "Epoch 53/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.45it/s, loss=3.29, acc=28]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.25it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.7614, Train Acc: 28.03%\n",
            "Val Loss: 2.8605, Val Acc: 26.23%\n",
            "✓ Saved new best model with Val Acc: 26.23%\n",
            "\n",
            "Epoch 54/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.49it/s, loss=2.59, acc=30.6]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.23it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.5405, Train Acc: 30.57%\n",
            "Val Loss: 2.7945, Val Acc: 26.78%\n",
            "✓ Saved new best model with Val Acc: 26.78%\n",
            "\n",
            "Epoch 55/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.46it/s, loss=2.17, acc=37.3]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.29it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.3892, Train Acc: 37.32%\n",
            "Val Loss: 2.7126, Val Acc: 24.04%\n",
            "\n",
            "Epoch 56/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.49it/s, loss=1.95, acc=40.4]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.31it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.2867, Train Acc: 40.38%\n",
            "Val Loss: 2.5571, Val Acc: 32.24%\n",
            "✓ Saved new best model with Val Acc: 32.24%\n",
            "\n",
            "Epoch 57/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.45it/s, loss=2.57, acc=44.2]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.25it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.1739, Train Acc: 44.20%\n",
            "Val Loss: 2.4685, Val Acc: 34.43%\n",
            "✓ Saved new best model with Val Acc: 34.43%\n",
            "\n",
            "Epoch 58/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.49it/s, loss=1.97, acc=47.4]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.30it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.0618, Train Acc: 47.39%\n",
            "Val Loss: 2.4989, Val Acc: 36.61%\n",
            "✓ Saved new best model with Val Acc: 36.61%\n",
            "\n",
            "Epoch 59/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.44it/s, loss=1.74, acc=49.6]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.10it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.9237, Train Acc: 49.55%\n",
            "Val Loss: 2.3463, Val Acc: 38.25%\n",
            "✓ Saved new best model with Val Acc: 38.25%\n",
            "\n",
            "Epoch 60/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.48it/s, loss=2.2, acc=54.5]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.8288, Train Acc: 54.52%\n",
            "Val Loss: 2.2851, Val Acc: 38.25%\n",
            "\n",
            "Epoch 61/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.42it/s, loss=2.34, acc=59.5]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.27it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.6606, Train Acc: 59.49%\n",
            "Val Loss: 2.2530, Val Acc: 40.98%\n",
            "✓ Saved new best model with Val Acc: 40.98%\n",
            "\n",
            "Epoch 62/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.51it/s, loss=1.8, acc=59.7]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.30it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.6403, Train Acc: 59.75%\n",
            "Val Loss: 2.2764, Val Acc: 37.70%\n",
            "\n",
            "Epoch 63/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.47it/s, loss=1.9, acc=63.6]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.17it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.5365, Train Acc: 63.57%\n",
            "Val Loss: 2.1051, Val Acc: 42.62%\n",
            "✓ Saved new best model with Val Acc: 42.62%\n",
            "\n",
            "Epoch 64/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.43it/s, loss=1.13, acc=66.6]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.22it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.4352, Train Acc: 66.62%\n",
            "Val Loss: 2.0866, Val Acc: 45.90%\n",
            "✓ Saved new best model with Val Acc: 45.90%\n",
            "\n",
            "Epoch 65/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.46it/s, loss=1.14, acc=66.9]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.16it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.3950, Train Acc: 66.88%\n",
            "Val Loss: 2.0875, Val Acc: 42.62%\n",
            "\n",
            "Epoch 66/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.46it/s, loss=1.3, acc=70.8]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.27it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2451, Train Acc: 70.83%\n",
            "Val Loss: 2.0766, Val Acc: 42.08%\n",
            "\n",
            "Epoch 67/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.47it/s, loss=0.735, acc=69.7]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2816, Train Acc: 69.68%\n",
            "Val Loss: 2.0692, Val Acc: 46.45%\n",
            "✓ Saved new best model with Val Acc: 46.45%\n",
            "\n",
            "Epoch 68/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.45it/s, loss=1.4, acc=70.7]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2723, Train Acc: 70.70%\n",
            "Val Loss: 2.0615, Val Acc: 46.45%\n",
            "\n",
            "Epoch 69/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.45it/s, loss=1.3, acc=74.6]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.0988, Train Acc: 74.65%\n",
            "Val Loss: 1.9641, Val Acc: 49.18%\n",
            "✓ Saved new best model with Val Acc: 49.18%\n",
            "\n",
            "Epoch 70/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.46it/s, loss=1.45, acc=76.8]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.28it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.0302, Train Acc: 76.82%\n",
            "Val Loss: 1.9666, Val Acc: 46.45%\n",
            "\n",
            "Epoch 71/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.48it/s, loss=1.4, acc=77.6]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.0405, Train Acc: 77.58%\n",
            "Val Loss: 1.9288, Val Acc: 48.63%\n",
            "\n",
            "Epoch 72/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.48it/s, loss=0.701, acc=78.1]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.27it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.9564, Train Acc: 78.09%\n",
            "Val Loss: 1.8915, Val Acc: 47.54%\n",
            "\n",
            "Epoch 73/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.50it/s, loss=0.993, acc=81]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.8819, Train Acc: 81.02%\n",
            "Val Loss: 1.8541, Val Acc: 47.54%\n",
            "\n",
            "Epoch 74/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:31<00:00,  1.40it/s, loss=0.695, acc=80.8]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.22it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.9185, Train Acc: 80.76%\n",
            "Val Loss: 1.8650, Val Acc: 51.91%\n",
            "✓ Saved new best model with Val Acc: 51.91%\n",
            "\n",
            "Epoch 75/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.49it/s, loss=1.52, acc=81.9]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.22it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.8089, Train Acc: 81.91%\n",
            "Val Loss: 1.8708, Val Acc: 49.18%\n",
            "\n",
            "Epoch 76/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.49it/s, loss=0.836, acc=81.3]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.30it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.8558, Train Acc: 81.27%\n",
            "Val Loss: 1.9113, Val Acc: 49.73%\n",
            "\n",
            "Epoch 77/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.45it/s, loss=0.913, acc=84.8]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.27it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7863, Train Acc: 84.84%\n",
            "Val Loss: 1.8274, Val Acc: 53.01%\n",
            "✓ Saved new best model with Val Acc: 53.01%\n",
            "\n",
            "Epoch 78/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.50it/s, loss=0.805, acc=84.6]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7505, Train Acc: 84.59%\n",
            "Val Loss: 1.8134, Val Acc: 50.27%\n",
            "\n",
            "Epoch 79/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:31<00:00,  1.41it/s, loss=0.989, acc=86.1]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6739, Train Acc: 86.11%\n",
            "Val Loss: 1.8501, Val Acc: 50.27%\n",
            "\n",
            "Epoch 80/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.49it/s, loss=0.17, acc=86.2]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6474, Train Acc: 86.24%\n",
            "Val Loss: 1.8430, Val Acc: 50.82%\n",
            "\n",
            "Epoch 81/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.49it/s, loss=0.997, acc=84.8]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6732, Train Acc: 84.84%\n",
            "Val Loss: 1.7903, Val Acc: 52.46%\n",
            "\n",
            "Epoch 82/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.49it/s, loss=0.763, acc=85.4]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.26it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6703, Train Acc: 85.35%\n",
            "Val Loss: 1.8184, Val Acc: 53.55%\n",
            "✓ Saved new best model with Val Acc: 53.55%\n",
            "\n",
            "Epoch 83/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.43it/s, loss=1.18, acc=89.7]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.28it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.5584, Train Acc: 89.68%\n",
            "Val Loss: 1.7497, Val Acc: 53.55%\n",
            "\n",
            "Epoch 84/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.44it/s, loss=0.683, acc=90.6]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4948, Train Acc: 90.57%\n",
            "Val Loss: 1.7738, Val Acc: 55.19%\n",
            "✓ Saved new best model with Val Acc: 55.19%\n",
            "\n",
            "Epoch 85/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.44it/s, loss=0.326, acc=89.8]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.5239, Train Acc: 89.81%\n",
            "Val Loss: 1.7679, Val Acc: 51.37%\n",
            "\n",
            "Epoch 86/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.47it/s, loss=0.423, acc=91]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4754, Train Acc: 90.96%\n",
            "Val Loss: 1.7090, Val Acc: 55.19%\n",
            "\n",
            "Epoch 87/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:31<00:00,  1.40it/s, loss=0.257, acc=90.4]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4622, Train Acc: 90.45%\n",
            "Val Loss: 1.7328, Val Acc: 54.64%\n",
            "\n",
            "Epoch 88/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.44it/s, loss=0.407, acc=90.4]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.27it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4772, Train Acc: 90.45%\n",
            "Val Loss: 1.7308, Val Acc: 53.55%\n",
            "\n",
            "Epoch 89/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.47it/s, loss=0.584, acc=91]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4783, Train Acc: 90.96%\n",
            "Val Loss: 1.7608, Val Acc: 55.74%\n",
            "✓ Saved new best model with Val Acc: 55.74%\n",
            "\n",
            "Epoch 90/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.49it/s, loss=1.09, acc=89]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.24it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.5174, Train Acc: 89.04%\n",
            "Val Loss: 1.7226, Val Acc: 51.37%\n",
            "\n",
            "Epoch 91/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.47it/s, loss=0.894, acc=91.8]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4139, Train Acc: 91.85%\n",
            "Val Loss: 1.7062, Val Acc: 53.55%\n",
            "\n",
            "Epoch 92/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.45it/s, loss=0.261, acc=91.7]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.27it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3984, Train Acc: 91.72%\n",
            "Val Loss: 1.7254, Val Acc: 54.10%\n",
            "\n",
            "Epoch 93/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.47it/s, loss=0.424, acc=90.2]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.22it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4722, Train Acc: 90.19%\n",
            "Val Loss: 1.7339, Val Acc: 54.10%\n",
            "\n",
            "Epoch 94/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.44it/s, loss=0.571, acc=90.2]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.23it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4596, Train Acc: 90.19%\n",
            "Val Loss: 1.7555, Val Acc: 52.46%\n",
            "\n",
            "Epoch 95/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.42it/s, loss=0.63, acc=90.6]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.07it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4253, Train Acc: 90.57%\n",
            "Val Loss: 1.7104, Val Acc: 54.10%\n",
            "\n",
            "Epoch 96/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.51it/s, loss=0.0747, acc=91.7]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.27it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4077, Train Acc: 91.72%\n",
            "Val Loss: 1.6896, Val Acc: 55.19%\n",
            "\n",
            "Epoch 97/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.48it/s, loss=0.412, acc=91.5]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4046, Train Acc: 91.46%\n",
            "Val Loss: 1.7616, Val Acc: 54.10%\n",
            "\n",
            "Epoch 98/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.45it/s, loss=0.244, acc=91.5]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4290, Train Acc: 91.46%\n",
            "Val Loss: 1.7854, Val Acc: 53.01%\n",
            "\n",
            "Epoch 99/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.45it/s, loss=1.04, acc=92.6]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3816, Train Acc: 92.61%\n",
            "Val Loss: 1.7215, Val Acc: 55.74%\n",
            "\n",
            "Epoch 100/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:31<00:00,  1.39it/s, loss=0.211, acc=93.8]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.28it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3316, Train Acc: 93.76%\n",
            "Val Loss: 1.7602, Val Acc: 53.55%\n",
            "\n",
            "Epoch 101/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.46it/s, loss=0.711, acc=92.1]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3643, Train Acc: 92.10%\n",
            "Val Loss: 1.7617, Val Acc: 55.19%\n",
            "\n",
            "Epoch 102/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.44it/s, loss=0.802, acc=92.6]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3320, Train Acc: 92.61%\n",
            "Val Loss: 1.7925, Val Acc: 50.82%\n",
            "\n",
            "Epoch 103/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.44it/s, loss=0.506, acc=91.8]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4037, Train Acc: 91.85%\n",
            "Val Loss: 1.7164, Val Acc: 54.10%\n",
            "\n",
            "Epoch 104/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.50it/s, loss=0.137, acc=93.9]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.14it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3089, Train Acc: 93.89%\n",
            "Val Loss: 1.7336, Val Acc: 53.01%\n",
            "\n",
            "Epoch 105/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.47it/s, loss=0.946, acc=91.5]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.27it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3900, Train Acc: 91.46%\n",
            "Val Loss: 1.7368, Val Acc: 51.91%\n",
            "\n",
            "Epoch 106/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.48it/s, loss=0.183, acc=93]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3554, Train Acc: 92.99%\n",
            "Val Loss: 1.7262, Val Acc: 54.10%\n",
            "\n",
            "Epoch 107/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.45it/s, loss=0.193, acc=94]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.31it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2817, Train Acc: 94.01%\n",
            "Val Loss: 1.6892, Val Acc: 55.19%\n",
            "\n",
            "Epoch 108/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.46it/s, loss=0.406, acc=94.4]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.31it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3107, Train Acc: 94.39%\n",
            "Val Loss: 1.6984, Val Acc: 52.46%\n",
            "\n",
            "Epoch 109/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.49it/s, loss=0.356, acc=94.5]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.16it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3048, Train Acc: 94.52%\n",
            "Val Loss: 1.6884, Val Acc: 54.64%\n",
            "\n",
            "Epoch 110/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.45it/s, loss=0.784, acc=93.2]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3159, Train Acc: 93.25%\n",
            "Val Loss: 1.6884, Val Acc: 54.64%\n",
            "\n",
            "Epoch 111/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.49it/s, loss=0.0953, acc=93.8]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3032, Train Acc: 93.76%\n",
            "Val Loss: 1.6841, Val Acc: 53.55%\n",
            "\n",
            "Epoch 112/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.49it/s, loss=0.336, acc=94]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2702, Train Acc: 94.01%\n",
            "Val Loss: 1.6735, Val Acc: 54.10%\n",
            "\n",
            "Epoch 113/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.48it/s, loss=0.249, acc=93.4]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3278, Train Acc: 93.38%\n",
            "Val Loss: 1.6831, Val Acc: 55.74%\n",
            "\n",
            "Epoch 114/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.45it/s, loss=0.635, acc=94.3]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.23it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2801, Train Acc: 94.27%\n",
            "Val Loss: 1.6931, Val Acc: 55.19%\n",
            "\n",
            "Epoch 115/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.50it/s, loss=0.172, acc=93.9]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.11it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2822, Train Acc: 93.89%\n",
            "Val Loss: 1.6724, Val Acc: 55.74%\n",
            "\n",
            "Epoch 116/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.51it/s, loss=0.527, acc=93.2]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3165, Train Acc: 93.25%\n",
            "Val Loss: 1.6748, Val Acc: 53.55%\n",
            "\n",
            "Epoch 117/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.44it/s, loss=0.65, acc=94.4]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.25it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2865, Train Acc: 94.39%\n",
            "Val Loss: 1.6580, Val Acc: 57.38%\n",
            "✓ Saved new best model with Val Acc: 57.38%\n",
            "\n",
            "Epoch 118/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.47it/s, loss=0.675, acc=93.8]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2829, Train Acc: 93.76%\n",
            "Val Loss: 1.6722, Val Acc: 54.10%\n",
            "\n",
            "Epoch 119/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.47it/s, loss=0.118, acc=93.5]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.26it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3150, Train Acc: 93.50%\n",
            "Val Loss: 1.6784, Val Acc: 55.19%\n",
            "\n",
            "Epoch 120/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.43it/s, loss=0.0634, acc=95.2]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.08it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2414, Train Acc: 95.16%\n",
            "Val Loss: 1.6678, Val Acc: 54.10%\n",
            "\n",
            "Epoch 121/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.47it/s, loss=0.454, acc=92.6]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.27it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3226, Train Acc: 92.61%\n",
            "Val Loss: 1.6910, Val Acc: 54.64%\n",
            "\n",
            "Epoch 122/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.44it/s, loss=0.291, acc=94.4]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2494, Train Acc: 94.39%\n",
            "Val Loss: 1.6588, Val Acc: 56.28%\n",
            "\n",
            "Epoch 123/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.50it/s, loss=0.304, acc=94.5]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.23it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2734, Train Acc: 94.52%\n",
            "Val Loss: 1.6505, Val Acc: 55.19%\n",
            "\n",
            "Epoch 124/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:31<00:00,  1.41it/s, loss=0.243, acc=93.9]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2836, Train Acc: 93.89%\n",
            "Val Loss: 1.7059, Val Acc: 54.10%\n",
            "\n",
            "Epoch 125/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [00:31<00:00,  1.40it/s, loss=0.0527, acc=94.9]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.23it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2574, Train Acc: 94.90%\n",
            "Val Loss: 1.6534, Val Acc: 54.10%\n",
            "\n",
            "Epoch 126/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.42it/s, loss=0.197, acc=93.9]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2825, Train Acc: 93.89%\n",
            "Val Loss: 1.6166, Val Acc: 55.19%\n",
            "\n",
            "Epoch 127/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.46it/s, loss=0.0642, acc=94.1]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2999, Train Acc: 94.14%\n",
            "Val Loss: 1.6903, Val Acc: 54.64%\n",
            "\n",
            "Epoch 128/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.48it/s, loss=0.175, acc=93.9]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2777, Train Acc: 93.89%\n",
            "Val Loss: 1.6649, Val Acc: 55.74%\n",
            "\n",
            "Epoch 129/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.45it/s, loss=0.443, acc=93.8]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2831, Train Acc: 93.76%\n",
            "Val Loss: 1.6473, Val Acc: 56.28%\n",
            "\n",
            "Epoch 130/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.46it/s, loss=0.158, acc=95.7]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2290, Train Acc: 95.67%\n",
            "Val Loss: 1.6302, Val Acc: 55.74%\n",
            "\n",
            "Epoch 131/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.45it/s, loss=0.224, acc=96.4]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2159, Train Acc: 96.43%\n",
            "Val Loss: 1.6559, Val Acc: 57.38%\n",
            "\n",
            "Epoch 132/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.46it/s, loss=0.265, acc=94.1]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2903, Train Acc: 94.14%\n",
            "Val Loss: 1.6621, Val Acc: 58.47%\n",
            "✓ Saved new best model with Val Acc: 58.47%\n",
            "\n",
            "Epoch 133/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.44it/s, loss=0.195, acc=94.5]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2458, Train Acc: 94.52%\n",
            "Val Loss: 1.6695, Val Acc: 54.64%\n",
            "\n",
            "Epoch 134/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.48it/s, loss=0.0653, acc=94.5]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2787, Train Acc: 94.52%\n",
            "Val Loss: 1.6354, Val Acc: 57.38%\n",
            "\n",
            "Epoch 135/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.43it/s, loss=0.467, acc=94.1]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2834, Train Acc: 94.14%\n",
            "Val Loss: 1.6566, Val Acc: 57.38%\n",
            "\n",
            "Epoch 136/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.43it/s, loss=0.0918, acc=95.5]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2315, Train Acc: 95.54%\n",
            "Val Loss: 1.6327, Val Acc: 55.74%\n",
            "\n",
            "Epoch 137/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.48it/s, loss=0.153, acc=94.6]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2749, Train Acc: 94.65%\n",
            "Val Loss: 1.6379, Val Acc: 56.83%\n",
            "\n",
            "Epoch 138/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:31<00:00,  1.39it/s, loss=0.134, acc=95.8]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2026, Train Acc: 95.80%\n",
            "Val Loss: 1.6463, Val Acc: 57.38%\n",
            "\n",
            "Epoch 139/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.42it/s, loss=0.14, acc=95.3]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2155, Train Acc: 95.29%\n",
            "Val Loss: 1.6353, Val Acc: 54.64%\n",
            "\n",
            "Epoch 140/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:28<00:00,  1.52it/s, loss=0.36, acc=94.5]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2683, Train Acc: 94.52%\n",
            "Val Loss: 1.6567, Val Acc: 56.28%\n",
            "\n",
            "Epoch 141/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.42it/s, loss=0.884, acc=94.4]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2595, Train Acc: 94.39%\n",
            "Val Loss: 1.6358, Val Acc: 56.28%\n",
            "\n",
            "Epoch 142/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.49it/s, loss=0.473, acc=94.8]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2567, Train Acc: 94.78%\n",
            "Val Loss: 1.6560, Val Acc: 56.83%\n",
            "\n",
            "Epoch 143/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.47it/s, loss=0.0554, acc=95.3]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2376, Train Acc: 95.29%\n",
            "Val Loss: 1.6515, Val Acc: 57.38%\n",
            "\n",
            "Epoch 144/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:31<00:00,  1.41it/s, loss=0.426, acc=93.8]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2848, Train Acc: 93.76%\n",
            "Val Loss: 1.6648, Val Acc: 56.28%\n",
            "\n",
            "Epoch 145/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.50it/s, loss=0.147, acc=94.4]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2762, Train Acc: 94.39%\n",
            "Val Loss: 1.6509, Val Acc: 57.38%\n",
            "\n",
            "Epoch 146/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.48it/s, loss=0.476, acc=94.1]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2670, Train Acc: 94.14%\n",
            "Val Loss: 1.6548, Val Acc: 57.92%\n",
            "\n",
            "Epoch 147/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.50it/s, loss=0.631, acc=95.8]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2089, Train Acc: 95.80%\n",
            "Val Loss: 1.6590, Val Acc: 57.38%\n",
            "\n",
            "Epoch 148/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.45it/s, loss=0.868, acc=93.6]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2904, Train Acc: 93.63%\n",
            "Val Loss: 1.6593, Val Acc: 56.83%\n",
            "\n",
            "Epoch 149/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.44it/s, loss=0.0798, acc=95.8]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2078, Train Acc: 95.80%\n",
            "Val Loss: 1.6359, Val Acc: 54.10%\n",
            "\n",
            "Epoch 150/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.50it/s, loss=0.0907, acc=95]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2468, Train Acc: 95.03%\n",
            "Val Loss: 1.6560, Val Acc: 56.83%\n",
            "\n",
            "Epoch 151/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.42it/s, loss=0.1, acc=94.5]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2659, Train Acc: 94.52%\n",
            "Val Loss: 1.6476, Val Acc: 56.28%\n",
            "\n",
            "Epoch 152/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.48it/s, loss=0.239, acc=93.2]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2967, Train Acc: 93.25%\n",
            "Val Loss: 1.6473, Val Acc: 55.74%\n",
            "\n",
            "Epoch 153/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.49it/s, loss=0.665, acc=95.5]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2110, Train Acc: 95.54%\n",
            "Val Loss: 1.6519, Val Acc: 56.28%\n",
            "\n",
            "Epoch 154/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:30<00:00,  1.44it/s, loss=0.164, acc=95.3]\n",
            "Evaluating: 100%|██████████| 11/11 [00:05<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2351, Train Acc: 95.29%\n",
            "Val Loss: 1.6607, Val Acc: 56.83%\n",
            "\n",
            "Epoch 155/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 44/44 [00:29<00:00,  1.51it/s, loss=0.145, acc=95]\n",
            "Evaluating: 100%|██████████| 11/11 [00:04<00:00,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2415, Train Acc: 95.03%\n",
            "Val Loss: 1.6646, Val Acc: 57.38%\n",
            "\n",
            "Epoch 156/200\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  66%|██████▌   | 29/44 [00:21<00:08,  1.73it/s, loss=0.17, acc=92.1]"
          ]
        }
      ],
      "source": [
        "from typing import *\n",
        "import os\n",
        "\n",
        "# Training loop\n",
        "best_val_acc = 0.0\n",
        "history = {\n",
        "    'train_loss': [], 'train_acc': [],\n",
        "    'val_loss': [], 'val_acc': []\n",
        "}\n",
        "\n",
        "from torch.utils.flop_counter import FlopCounterMode\n",
        "\n",
        "def get_flops(model, inp: Union[torch.Tensor, Tuple], with_backward=False):\n",
        "\n",
        "    istrain = model.training\n",
        "    model.eval()\n",
        "\n",
        "    inp = inp if isinstance(inp, torch.Tensor) else torch.randn(inp)\n",
        "\n",
        "    flop_counter = FlopCounterMode(mods=model, display=False, depth=None)\n",
        "    with flop_counter:\n",
        "        if with_backward:\n",
        "            model(inp).sum().backward()\n",
        "        else:\n",
        "            model(inp)\n",
        "    total_flops =  flop_counter.get_total_flops()\n",
        "    if istrain:\n",
        "        model.train()\n",
        "    return total_flops\n",
        "\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "FOLDER_PATH = \"/content/drive/MyDrive/Intro_2_DL\"\n",
        "MODEL_NAME = f\"2d_cnn_lstm_wlasl{CLASSES_COUNT}.pth\"\n",
        "MODEL_PATH = os.path.join(FOLDER_PATH, MODEL_NAME)\n",
        "CONTINUE = True\n",
        "start_epoch = 0\n",
        "\"\"\"\n",
        "  'epoch': epoch,\n",
        "  'model_state_dict': model.state_dict(),\n",
        "  'optimizer_state_dict': optimizer.state_dict(),\n",
        "  'val_acc': val_acc,\n",
        "  'label_map': train_dataset.label_map\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "  if CONTINUE:\n",
        "      checkpoint = torch.load(MODEL_PATH)\n",
        "      optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "      start_epoch = checkpoint['epoch'] + 1\n",
        "      model.load_state_dict(checkpoint['model_state_dict'])\n",
        "      # val_acc.extend(checkpoint['val_acc'])\n",
        "except:\n",
        "  pass\n",
        "\n",
        "\n",
        "for epoch in range(start_epoch, NUM_EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n",
        "    print(\"-\" * 40)\n",
        "    if epoch > EPOCHS_UNTIL_UNFREEZE and FREEZE_CNN:\n",
        "        model.set_freeze(False)\n",
        "    # Train\n",
        "\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    # train_flops = get_flops(model, )\n",
        "    # Validate\n",
        "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "    # Update scheduler\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Save history\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_acc': val_acc,\n",
        "            'label_map': train_dataset.label_map\n",
        "        }, MODEL_PATH)\n",
        "        print(f\"✓ Saved new best model with Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "print(f\"\\nTraining complete! Best Val Acc: {best_val_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gcTgeR1V1TXz",
        "outputId": "97abd6db-f66c-4e5e-d4eb-b8ffd507a298",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0_AbauW-lmm"
      },
      "source": [
        "## 9. Evaluation and Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxMS0YFc-lmm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training history\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Loss plot\n",
        "axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
        "axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Training and Validation Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True)\n",
        "\n",
        "# Accuracy plot\n",
        "axes[1].plot(history['train_acc'], label='Train Acc', marker='o')\n",
        "axes[1].plot(history['val_acc'], label='Val Acc', marker='s')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Accuracy (%)')\n",
        "axes[1].set_title('Training and Validation Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_history.png', dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "N5fEQd22-lmm",
        "outputId": "7130477f-f04c-4952-8f46-3d3f4a18b8e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/2 [00:00<?, ?it/s]/tmp/ipython-input-3634111461.py:63: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Evaluating: 100%|██████████| 2/2 [00:01<00:00,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Results:\n",
            "Test Loss: 1.1794\n",
            "Test Accuracy: 77.14%\n",
            "{'book': 0, 'drink': 1, 'computer': 2, 'before': 3, 'chair': 4, 'go': 5, 'clothes': 6, 'who': 7, 'candy': 8, 'cousin': 9}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Load best model and evaluate on test set\n",
        "checkpoint = torch.load('/content/drive/MyDrive/Intro_2_DL/2d_cnn_lstm_wlasl10.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "print(f\"\\nTest Results:\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "print(test_loader.dataset.label_map)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Video\n",
        "\n",
        "Video(\"/content/test.mp4\", embed=True)"
      ],
      "metadata": {
        "id": "uwkMuXON0DRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK5qG01d-lmn"
      },
      "source": [
        "## 10. Attention Visualization\n",
        "\n",
        "Visualize which frames the model attends to most when making predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY2JOSmH-lmn"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def visualize_attention(model, frames, true_label, label_map, device):\n",
        "    \"\"\"Visualize attention weights over video frames.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Get reverse label map\n",
        "    idx_to_label = {v: k for k, v in label_map.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Add batch dimension\n",
        "        frames_batch = frames.unsqueeze(0).to(device)\n",
        "\n",
        "        # Get predictions and attention weights\n",
        "        logits, attention_weights = model(frames_batch, return_attention=True)\n",
        "        pred_label = torch.argmax(logits, dim=1).item()\n",
        "        attention = attention_weights[0].cpu().numpy()\n",
        "\n",
        "    # Create visualization\n",
        "    num_frames = frames.shape[0]\n",
        "    fig, axes = plt.subplots(2, num_frames, figsize=(2 * num_frames, 6))\n",
        "\n",
        "    # Denormalize frames for visualization\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "\n",
        "    for i in range(num_frames):\n",
        "        frame = frames[i].cpu()\n",
        "        frame = frame * std + mean\n",
        "        frame = frame.clamp(0, 1).permute(1, 2, 0).numpy()\n",
        "\n",
        "        # Frame image\n",
        "        axes[0, i].imshow(frame)\n",
        "        axes[0, i].set_title(f\"Frame {i+1}\")\n",
        "        axes[0, i].axis('off')\n",
        "\n",
        "        # Attention weight bar\n",
        "        axes[1, i].bar([0], [attention[i]], color='blue', alpha=0.7)\n",
        "        axes[1, i].set_ylim(0, max(attention) * 1.2)\n",
        "        axes[1, i].set_title(f\"{attention[i]:.3f}\")\n",
        "        axes[1, i].axis('off')\n",
        "\n",
        "    plt.suptitle(\n",
        "        f\"True: {idx_to_label.get(true_label, true_label)} | \"\n",
        "        f\"Predicted: {idx_to_label.get(pred_label, pred_label)}\",\n",
        "        fontsize=14\n",
        "    )\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return pred_label, attention\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pOEoPik-lmn"
      },
      "outputs": [],
      "source": [
        "# Visualize attention for a sample from the test set\n",
        "sample_idx = 0\n",
        "frames, label = test_dataset[sample_idx]\n",
        "pred, attn = visualize_attention(model, frames, label, train_dataset.label_map, device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1vGI8IA-lmn"
      },
      "source": [
        "## 11. Inference Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "6CXDTtOc-lmn"
      },
      "outputs": [],
      "source": [
        "def predict_video(model, video_path, transform, num_frames, label_map, device):\n",
        "    \"\"\"Predict the sign language class for a video file.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Get reverse label map\n",
        "    idx_to_label = {v: k for k, v in label_map.items()}\n",
        "\n",
        "    # Decode video\n",
        "    decoder = VideoDecoder(video_path)\n",
        "    frames = transform(decoder[:])\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        frames_batch = frames.unsqueeze(0).to(device)\n",
        "        logits, attention = model(frames_batch, return_attention=True)\n",
        "        probabilities = F.softmax(logits, dim=1)\n",
        "        pred_idx = torch.argmax(logits, dim=1).item()\n",
        "        confidence = probabilities[0, pred_idx].item()\n",
        "        # print(probabilities[0])\n",
        "        confidence_map = {k:probabilities[0][v] for k, v in label_map.items()}\n",
        "\n",
        "    predicted_label = idx_to_label.get(pred_idx, f\"Unknown ({pred_idx})\")\n",
        "\n",
        "    return {\n",
        "        'prediction': predicted_label,\n",
        "        'confidence': confidence,\n",
        "        'attention_weights': attention[0].cpu().numpy(),\n",
        "        'all_probabilities': probabilities[0].cpu().numpy(),\n",
        "        'confidence_map': confidence_map\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "1SNQvsPo-lmn",
        "outputId": "4cb710ba-4e5c-40ff-bd43-036a883287a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prediction': 'clothes',\n",
              " 'confidence': 0.38274869322776794,\n",
              " 'attention_weights': array([0.0020458 , 0.00242777, 0.00301321, 0.00372175, 0.00546827,\n",
              "        0.00813784, 0.01599127, 0.03130766, 0.05722787, 0.09245452,\n",
              "        0.13012624, 0.17093936, 0.16195637, 0.13383292, 0.08268953,\n",
              "        0.04849194, 0.02445068, 0.01156051, 0.00566186, 0.00293349,\n",
              "        0.00176526, 0.00131966, 0.00119694, 0.00127926], dtype=float32),\n",
              " 'all_probabilities': array([0.1414117 , 0.00289593, 0.09375774, 0.09477092, 0.02518048,\n",
              "        0.04935614, 0.3827487 , 0.05513893, 0.14449586, 0.01024358],\n",
              "       dtype=float32),\n",
              " 'confidence_map': {'book': tensor(0.1414, device='cuda:0'),\n",
              "  'drink': tensor(0.0029, device='cuda:0'),\n",
              "  'computer': tensor(0.0938, device='cuda:0'),\n",
              "  'before': tensor(0.0948, device='cuda:0'),\n",
              "  'chair': tensor(0.0252, device='cuda:0'),\n",
              "  'go': tensor(0.0494, device='cuda:0'),\n",
              "  'clothes': tensor(0.3827, device='cuda:0'),\n",
              "  'who': tensor(0.0551, device='cuda:0'),\n",
              "  'candy': tensor(0.1445, device='cuda:0'),\n",
              "  'cousin': tensor(0.0102, device='cuda:0')}}"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "# Example inference (uncomment and modify path to use)\n",
        "result = predict_video(\n",
        "    model=model,\n",
        "    video_path=\"/content/test3.mp4\",\n",
        "    transform=val_transform,\n",
        "    num_frames=NUM_FRAMES,\n",
        "    label_map=train_dataset.label_map,\n",
        "    device=device\n",
        ")\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Srt60SNL-lmn"
      },
      "source": [
        "## 12. Save Final Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpDygB68-lmo"
      },
      "outputs": [],
      "source": [
        "# Save complete model for deployment\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'label_map': train_dataset.label_map,\n",
        "    'config': {\n",
        "        'num_classes': NUM_CLASSES,\n",
        "        'feature_dim': FEATURE_DIM,\n",
        "        'hidden_dim': HIDDEN_DIM,\n",
        "        'num_lstm_layers': NUM_LSTM_LAYERS,\n",
        "        'num_frames': NUM_FRAMES,\n",
        "        'dropout': DROPOUT\n",
        "    }\n",
        "}, 'sign2text_model_final.pth')\n",
        "\n",
        "print(\"Model saved to sign2text_model_final.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7qt1Yws-lmo"
      },
      "source": [
        "---\n",
        "**Note:** The cells above contain the complete implementation. Make sure to run them in order from top to bottom.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6VTtt4e-lmo"
      },
      "outputs": [],
      "source": [
        "# PositionalEncoding class is defined below cell 7 - this cell can be ignored\n",
        "# The model requires running cells in sequential order\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}